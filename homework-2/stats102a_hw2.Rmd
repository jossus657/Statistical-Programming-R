---
title: "Stats 102a HW 2"
author: "Joshua Susanto"
date: '2023-02-05'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("405568250_stats102a_hw2.R")
```

## Question 1

(a) Create a simulated dataset in R called gradebook that represents a possible gradebook in
the basic format as Table 1:
• Each row of the gradebook should contain all measurements for a student.
• Each column should contain scores for one assignment.
• The last column should be “Quiz_5.”
The simulated gradebook should contain the grades for 100 students and scores (out of
100) for 5 homework and 5 quizzes. Set the seed for simulating your data with your UID.

```{r}
set.seed(405568250)
library(tidyverse)
gradebook <- data.frame(UID = runif(100, 111111111, 10^9) %/% 1, 
                        Homework_1 = runif(100, 0, 100) %/% 1,
                        Homework_2 = runif(100, 0, 100) %/% 1,
                        Homework_3 = runif(100, 0, 100) %/% 1,
                        Homework_4 = runif(100, 0, 100) %/% 1,
                        Homework_5 = runif(100, 0, 100) %/% 1,
                        Quiz_1 = runif(100, 0, 100) %/% 1,
                        Quiz_2 = runif(100, 0, 100) %/% 1,
                        Quiz_3 = runif(100, 0, 100) %/% 1,
                        Quiz_4 = runif(100, 0, 100) %/% 1,
                        Quiz_5 = runif(100, 0, 100) %/% 1)
```

(b) Write R code in R markdown file to randomly replace 10% of Homework_4 and Quiz_4 by
NA respectively, and then use is.na() in conjunction with sum() to show your results.

```{r}
gradebook$Homework_4[floor(runif(10,1,100))] <- NA
gradebook$Quiz_4[floor(runif(10,1,100))] <- NA
sum(is.na(gradebook$Homework_4))
sum(is.na(gradebook$Quiz_4))
```

(c) Write a function messy_impute() that imputes missing values in the gradebook. Please
also present your algorithm or flowchart to answer this question in the R markdown file.


#### **`messy_impute`**

**Algorithm:**

1. Check for errors and undesirable inputs.

2. Check if the center is mean or median

3. For margin = 2 Use apply(), rowSums(), and which() in order to figure out which rows have missing values. Apply will iterate over the data frame and use is.na to return a matrix that tells which observations have NA. rowSums will sum all of the rows using coercion and finally using which will help locate which rows have NAs (as their row sum will be greater than 0)

4. Loop across every index found in step 3. Find the imputation for homework specific and quiz specific observations. This imputation is found by using mean() (or median()) on the row with the specified index. The split in homework vs quiz is done using the select function to split the dataframe into one with homeworks and one with quizzes.

5. Loop for every column on this row and see if the specific values are NA. If the value is NA then check if the column is a homework or quiz column and impute with the respective imputation.

6. Repeat steps 4 and 5 for every row with an NA value

7. If margin is equal to 1 then we find which columns have any NA values with the same process as step 3, except we use colSums() instead. For our imputation, we repeat the steps in 4 and 5 except with the iteration of rows and columns being swapped. 


(d) Select two students missing Homework_4 and two students missing Quiz_4. Please use
these cases to demonstrate your function in the R markdown file. Here are some suggested
cases but not limited to while grading.

Creating a subset with the first two missing homeworks and quizzes:
```{r}
missing_hw <- which(is.na(gradebook[, "Homework_4"]))
missing_hw <- missing_hw[1:2]
missing_quiz <- which(is.na(gradebook[, "Quiz_4"]))
missing_quiz <- missing_quiz[1:2]
missing_gradebook <- gradebook[c(missing_hw, missing_quiz),]
missing_gradebook
```

**Test Cases:**
```{r}
messy_impute(missing_gradebook, center = 'mean', margin = 2)
```
```{r error=TRUE}
messy_impute(missing_gradebook, 'mean', margin = 3, trim = 0.25)
```
```{r}
messy_impute(missing_gradebook, 'mean', margin = 1, trim = 0.25)
```
```{r}
messy_impute(missing_gradebook, 'median', 1, trim = 0.25)
```
```{r}
messy_impute(missing_gradebook, 'median', 2)
```


(e) Write R code using the main function in the tidyr package to convert the gradebook into
the tidy format. Name this object gradebook_tidy. You may directly write code in the R
markdown file.

```{r}
gradebook_tidy <- as_tibble(gradebook) %>% pivot_longer(cols = names(gradebook)[-1], names_to = 'Assignment', values_to = 'Score') %>% separate(Assignment, into = c('AssignmentType', 'AssignmentNumber'))
head(gradebook_tidy, 10)
```


(f) Write a function tidy_impute() that imputes missing values in gradebook_tidy object.
The tidy_impute() function should have the same arguments as in the messy_impute()
function. You should return an imputed gradebook_tidy object. Please also present your
algorithm or flowchart to answer this question in the R markdown file.
Note: Don’t convert gradebook_tidy object to be a messy format or reuse your
messy_impute() in any steps of your tidy_impute().

#### **`tidy_impute`**

**Algorithm:**

1. Check for errors and undesirable inputs.

2. Check if the center is mean or median

3. For margin = 2 similarly to messy_impute(), we use apply(), rowSums(), and which() in order to figure out which rows have missing values. Apply will iterate over the data frame and use is.na to return a matrix that tells which observations have NA. rowSums will sum all of the rows using coercion and finally using which will help locate which rows have NAs (as their row sum will be greater than 0)

4. Loop across every index found in step 3. For every index we find the UID of that observation. Then we use group_by() to group by UID and summarize() to find the means (or medians) of each person with this UID. We then use filter() with our ID to find the correct imputation for this specific index and replace the value accordingly.

5. For margin = 1, we repeat step 3 as the process is the same with a tidy dataset.

6. 

7. If margin is equal to 1 then we find which columns have any NA values with the same process as step 3, except we use colSums() instead. For our imputation, we repeat the steps in 4 and 5 except with the iteration of rows and columns being swapped. 



(g) Please use the cases you select from (d) to demonstrate your function in the R markdown
file.


**Test Cases:**
```{r}
tidy_impute(gradebook_tidy, center = 'mean', margin = 2)
```
```{r error=TRUE}
tidy_impute(gradebook_tidy, 'mean', margin = 3, trim = 0.25)
```
```{r}
tidy_impute(gradebook_tidy, 'mean', margin = 1, trim = 0.25)
```
```{r}
tidy_impute(gradebook_tidy, 'median', 1, trim = 0.25)
```
```{r}
tidy_impute(gradebook_tidy, 'median', 1)
```

## Question 2

(a) Please find three examples in which data might naturally be presented in a messy (non-tidy)
way. For each example, include the context, observations, and variables that would be
recorded. Showcase a small sample, say 10 observations, for each example. You may search
online for context, but you MUST cite your sources. Please don’t make up data on your
own.

i've included the datasets found online in the homework folder

1. movies.csv
```{r}
movies <- read_csv('movies.csv')
head(movies, 10)
```
A dataset depicting movies/shows and their attributes may be untidy. Often times the names of the people who worked on the movie will be grouped up into one variable even though each person had their own role that could be categorized differently.
I found this dataset on kaggle (https://www.kaggle.com/datasets/bharatnatrayn/movies-dataset-for-feature-extracion-prediction?resource=download) and it is data scrapped from imdb which highlights different movies and their features.


1. movies
```{r}
movies <- read_csv('movies.csv')
head(movies, 10)
```
A dataset depicting movies/shows and their attributes may be untidy. Often times the names of the people who worked on the movie will be grouped up into one variable even though each person had their own role that could be categorized differently.
SOURCE: I found this dataset on kaggle (https://www.kaggle.com/datasets/bharatnatrayn/movies-dataset-for-feature-extracion-prediction?resource=download) and it is data scrapped from imdb which highlights different movies and their features.

2. iPhone information
Another common form of messy data is how many tech companies display the specs of their devices. Many times the variables would be name of the product, spec 1, and other different specs. For example, many people would compare iPhones between each other by having the categories be something like storage or battery life with the observations being the price. This is messy as these categories should be their own observations and price needs its own category as well. 

```{r}
phones <- data.frame('model' = c('14 Pro Max', '14 Plus', '14 Pro'),
                    '128 GB' = c(1099, 899, 999), 
                    '256GB' = c(1199, 999, 1099),
                    '512GB' = c(1399, 1199, 1299))
phones
```

SOURCE: https://socialcompare.com/en/comparison/apple-iphone-product-line-comparison
https://www.apple.com/shop/buy-iphone/iphone-14-pro

3. Plane ticket data
Similarly to iPhone information, airlines or travel search engines can also display their data in an untidy way. People often chart their prices and separate categories by the type of ticket. For example, a price comparison chart can see the airline name as a category with the other categories being the different ticket levels (business, economy, first-class, etc) with their observations being the price for those different tickets. This is incorrect as the different categories should be observations for a broader category. Additionally, price needs to have its own category as well. These charts can also put the different airlines or travel search engines as different categories as well which has the same issue.

```{r}
planes <- data.frame('trip' = c('LA to NY', 'LA to NY', 'LA to NY', 'FL to NJ', 'FL to NJ', 'FL to NJ' ),
                    'Days until travel date' = c(2, 60, 120, 2, 60, 120),
                    'Travelocity' = c(521, 279, 308, 454, 424, 442), 
                    'Kayak' = c(529, 279, 345, 500, 414, 434),
                    'Hotwire' = c(522, 279, 381, 455, 435, 443))
planes
```

SOURCE: https://lenpenzo.com/blog/id1104-expedia-orbitz-priceline-and-others-a-comparison-of-travel-search-engines.html

(b) For each of the three examples in (a), describe how the data might be better presented in a
tidy way. Please use tidyverse functions to reorganize the small sample datasets in (a) into
tidy format.

Our movies data can be improve by separating the stars categrory into separate columns for 'director' and 'stars'. This can be done using the separate
```{r}
movies <- movies %>% separate(col = 'STARS', into = c('Director', 'Stars'), sep = 'Stars:')
head(movies, n = 10)
```

iPhones can be improved by creating a category for the different storage amounts instead of having those as separate categories. Price needs its own as well and we can do this through pivot longer
```{r}
phones
phones %>% pivot_longer(cols = c('X128.GB', 'X256GB', 'X512GB'), names_to = 'storage', values_to = 'price')
```


Planes can be improved by creating a category for the different websites instead of having those as separate categories. Price needs its own as well and we can do this through pivot longer
```{r}
planes %>% pivot_longer(cols = c('Travelocity', 'Kayak', 'Hotwire'), names_to = 'website', values_to = 'price')
```
